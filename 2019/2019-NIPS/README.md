# 2019-NIPS Accepted Papers

 - [[1]. Staying up to Date with Online Content Changes Using Reinforcement Learning for Scheduling.](https://proceedings.neurips.cc/paper/2019/hash/ad13a2a07ca4b7642959dc0c4c740ab6-Abstract.html)
 - [[2]. Regret Minimization for Reinforcement Learning with Vectorial Feedback and Complex Objectives.](https://proceedings.neurips.cc/paper/2019/hash/a02ffd91ece5e7efeb46db8f10a74059-Abstract.html)
 - [[3]. Value Propagation for Decentralized Networked Deep Multi-agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/8a0e1141fd37fa5b98d5bb769ba1a7cc-Abstract.html)
 - [[4]. Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards.](https://proceedings.neurips.cc/paper/2019/hash/81e74d678581a3bb7a720b019f4f1a93-Abstract.html)
 - [[5]. Multi-View Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/677e09724f0e2df9b6c000b75b5da10d-Abstract.html)
 - [[6]. Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update.](https://proceedings.neurips.cc/paper/2019/hash/e6d8545daa42d5ced125a4bf747b3688-Abstract.html)
 - [[7]. Information-Theoretic Confidence Bounds for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/411ae1bf081d1674ca6091f8c59a266f-Abstract.html)
 - [[8]. Regret Minimization for Reinforcement Learning by Evaluating the Optimal Bias Function.](https://proceedings.neurips.cc/paper/2019/hash/9e984c108157cea74c894b5cf34efc44-Abstract.html)
 - [[9]. Real-Time Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/54e36c5ff5f6a1802925ca009f3ebb68-Abstract.html)
 - [[10]. Convergent Policy Optimization for Safe Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/db29450c3f5e97f97846693611f98c15-Abstract.html)
 - [[11]. Efficient Communication in Multi-Agent Reinforcement Learning via Variance Based Control.](https://proceedings.neurips.cc/paper/2019/hash/14cfdb59b5bda1fc245aadae15b1984a-Abstract.html)
 - [[12]. Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/59bcda7c438bad7d2afffe9e2fed00be-Abstract.html)
 - [[13]. Learner-aware Teaching: Inverse Reinforcement Learning with Preferences and Constraints.](https://proceedings.neurips.cc/paper/2019/hash/3de568f8597b94bda53149c7d7f5958c-Abstract.html)
 - [[14]. Propagating Uncertainty in Reinforcement Learning via Wasserstein Barycenters.](https://proceedings.neurips.cc/paper/2019/hash/f83630579d055dc5843ae693e7cdafe0-Abstract.html)
 - [[15]. A Geometric Perspective on Optimal Representations for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/3cf2559725a9fdfa602ec8c887440f32-Abstract.html)
 - [[16]. LIIR: Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/07a9d3fed4c5ea6b17e80258dee231fa-Abstract.html)
 - [[17]. Finite-Time Performance Bounds and Adaptive Learning Rate Selection for Two Time-Scale Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/e354fd90b2d5c777bfec87a352a18976-Abstract.html)
 - [[18]. Adaptive Auxiliary Task Weighting for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/0e900ad84f63618452210ab8baae0218-Abstract.html)
 - [[19]. A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/c1b70d965ca504aa751ddb62ad69c63f-Abstract.html)
 - [[20]. A Regularized Approach to Sparse Optimal Policy in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/3f4366aeb9c157cf9a30c90693eafc55-Abstract.html)
 - [[21]. Fully Parameterized Quantile Function for Distributional Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/f471223d1a1614b58a7dc45c9d01df19-Abstract.html)
 - [[22]. Distributional Reward Decomposition for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/97108695bd93b6be52fa0334874c8722-Abstract.html)
 - [[23]. On the Correctness and Sample Complexity of Inverse Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/42c8938e4cf5777700700e642dc2a8cd-Abstract.html)
 - [[24]. VIREL: A Variational Inference Framework for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/582967e09f1b30ca2539968da0a174fa-Abstract.html)
 - [[25]. Non-Stationary Markov Decision Processes, a Worst-Case Approach using Model-Based Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/859b00aec8885efc83d1541b52a1220d-Abstract.html)
 - [[26]. Explicit Planning for Efficient Exploration in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/486c825db2f776da72d0b7a791f45b8f-Abstract.html)
 - [[27]. Constrained Reinforcement Learning Has Zero Duality Gap.](https://proceedings.neurips.cc/paper/2019/hash/c1aeb6517a1c7f33514f7ff69047e74e-Abstract.html)
 - [[28]. SMILe: Scalable Meta Inverse Reinforcement Learning through Context-Conditional Policies.](https://proceedings.neurips.cc/paper/2019/hash/2b8f621e9244cea5007bac8f5d50e476-Abstract.html)
 - [[29]. A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/3c3c139bd8467c1587a41081ad78045e-Abstract.html)
 - [[30]. Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function Gradient Estimators for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/6fd6b030c6afec018415662d0db43f9d-Abstract.html)
 - [[31]. Budgeted Reinforcement Learning in Continuous State Space.](https://proceedings.neurips.cc/paper/2019/hash/4fe5149039b52765bde64beb9f674940-Abstract.html)
 - [[32]. Language as an Abstraction for Hierarchical Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/0af787945872196b42c9f73ead2565c8-Abstract.html)
 - [[33]. Non-Cooperative Inverse Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/56bd37d3a2fda0f2f41925019c81011d-Abstract.html)
 - [[34]. Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling.](https://proceedings.neurips.cc/paper/2019/hash/4ffb0d2ba92f664c2281970110a2e071-Abstract.html)
 - [[35]. Multi-Agent Common Knowledge Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/f968fdc88852a4a3a27a81fe3f57bfc5-Abstract.html)
 - [[36]. Regularized Anderson Acceleration for Off-Policy Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/bb1443cc31d7396bf73e7858cea114e1-Abstract.html)
 - [[37]. Unsupervised Curricula for Visual Meta-Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/d5a28f81834b6df2b6db6d3e5e2635c7-Abstract.html)
 - [[38]. A Model-Based Reinforcement Learning with Adversarial Training for Online Recommendation.](https://proceedings.neurips.cc/paper/2019/hash/e49eb6523da9e1c347bc148ea8ac55d3-Abstract.html)
 - [[39]. Meta-Inverse Reinforcement Learning with Probabilistic Context Variables.](https://proceedings.neurips.cc/paper/2019/hash/30de24287a6d8f07b37c716ad51623a7-Abstract.html)
 - [[40]. Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies.](https://proceedings.neurips.cc/paper/2019/hash/25caef3a545a1fff2ff4055484f0e758-Abstract.html)
 - [[41]. Towards Interpretable Reinforcement Learning Using Attention Augmented Agents.](https://proceedings.neurips.cc/paper/2019/hash/e9510081ac30ffa83f10b68cde1cac07-Abstract.html)
 - [[42]. Regret Bounds for Learning State Representations in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/9b8b50fb590c590ffbf1295ce92258dc-Abstract.html)
 - [[43]. A Composable Specification Language for Reinforcement Learning Tasks.](https://proceedings.neurips.cc/paper/2019/hash/f5aa4bd09c07d8b2f65bad6c7cd3358f-Abstract.html)
 - [[44]. The Option Keyboard: Combining Skills in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/251c5ffd6b62cc21c446c963c76cf214-Abstract.html)
 - [[45]. Biases for Emergent Communication in Multi-agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/fe5e7cb609bdbe6d62449d61849c38b0-Abstract.html)
 - [[46]. Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/a1a527267c0d33a86382a03c4c721cd2-Abstract.html)
 - [[47]. Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes.](https://proceedings.neurips.cc/paper/2019/hash/8252831b9fce7a49421e622c14ce0f65-Abstract.html)
 - [[48]. Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck.](https://proceedings.neurips.cc/paper/2019/hash/e2ccf95a7f2e1878fcafc8376649b6e8-Abstract.html)
 - [[49]. Reinforcement Learning with Convex Constraints.](https://proceedings.neurips.cc/paper/2019/hash/873be0705c80679f2c71fbf4d872df59-Abstract.html)
 - [[50]. Using a Logarithmic Mapping to Enable Lower Discount Factors in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/eba237eccc24353ccaa4d62013556ac6-Abstract.html)
 - [[51]. Correlation Priors for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/1bd2caf96a17d892c2c7e9959549cfc7-Abstract.html)
 - [[52]. Policy Poisoning in Batch Reinforcement Learning and Control.](https://proceedings.neurips.cc/paper/2019/hash/315f006f691ef2e689125614ea22cc61-Abstract.html)
 - [[53]. A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation.](https://proceedings.neurips.cc/paper/2019/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html)
 - [[54]. Text-Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/52130c418d4f02c74f74a5bc1f8020b2-Abstract.html)
 - [[55]. Search on the Replay Buffer: Bridging Planning and Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/5c48ff18e0a47baaf81d8b8ea51eec92-Abstract.html)
 - [[56]. Learning Reward Machines for Partially Observable Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/532435c44bec236b471a47a88d63513d-Abstract.html)
 - [[57]. A Family of Robust Stochastic Operators for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/a44ba9086b2b83ccf2baf7c678723449-Abstract.html)
 - [[58]. Imitation-Projected Programmatic Reinforcement Learning.](https://proceedings.neurips.cc/paper/2019/hash/5a44a53b7d26bb1e54c05222f186dcfb-Abstract.html)
