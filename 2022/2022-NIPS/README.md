# 2022-NIPS Accepted Papers

 - [[[1]. Adaptive Interest for Emphatic <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/008079ec00eec9760ee93af5434ee932-Abstract-Conference.html)]
 - [[[2]. Offline Multi-Agent <font color='black'>*Reinforcement Learning*</font> with Knowledge Distillation.](http://papers.nips.cc/paper_files/paper/2022/hash/01d78b294d80491fecddea897cf03642-Abstract-Conference.html)]
 - [[[3]. Offline Goal-Conditioned <font color='black'>*Reinforcement Learning*</font> via $f$-Advantage Regression.](http://papers.nips.cc/paper_files/paper/2022/hash/022a39052abf9ca467e268923057dfc0-Abstract-Conference.html)]
 - [[[4]. Model-Based Offline <font color='black'>*Reinforcement Learning*</font> with Pessimism-Modulated Dynamics Belief.](http://papers.nips.cc/paper_files/paper/2022/hash/03469b1a66e351b18272be23baf3b809-Abstract-Conference.html)]
 - [[[5]. Identifiability and generalizability from multiple experts in Inverse <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/03bdba50e3741ac5e3eaa0e55423587e-Abstract-Conference.html)]
 - [[[6]. Provably Efficient <font color='black'>*Reinforcement Learning*</font> in Partially Observable Dynamical Systems.](http://papers.nips.cc/paper_files/paper/2022/hash/03d7e13f0092405804f3a381ade8f3f0-Abstract-Conference.html)]
 - [[[7]. Tiered <font color='black'>*Reinforcement Learning*</font>: Pessimism in the Face of Uncertainty and Constant Regret.](http://papers.nips.cc/paper_files/paper/2022/hash/0463ec87d0ac1e98a6cbe3d95d4e3e35-Abstract-Conference.html)]
 - [[[8]. DOPE: Doubly Optimistic and Pessimistic Exploration for Safe <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/076a93fd42aa85f5ccee921a01d77dd5-Abstract-Conference.html)]
 - [[[9]. LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/0b4145b562cc22fb7fa50a2cd17c191d-Abstract-Conference.html)]
 - [[[10]. Mildly Conservative Q-Learning for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/0b5669c3b07bb8429af19a7919376ff5-Abstract-Conference.html)]
 - [[[11]. <font color='black'>*Reinforcement Learning*</font> with Automated Auxiliary Loss Search.](http://papers.nips.cc/paper_files/paper/2022/hash/0be44cc1d459731928501cae5699f57a-Abstract-Conference.html)]
 - [[[12]. FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/0bf54b80686d2c4dc0808c2e98d430f7-Abstract-Datasets_and_Benchmarks.html)]
 - [[[13]. Incrementality Bidding via <font color='black'>*Reinforcement Learning*</font> under Mixed and Delayed Rewards.](http://papers.nips.cc/paper_files/paper/2022/hash/0ee633a6ade45eab4276352b3ee79c7a-Abstract-Conference.html)]
 - [[[14]. Monte Carlo Augmented Actor-Critic for Sparse Reward Deep <font color='black'>*Reinforcement Learning*</font> from Suboptimal Demonstrations.](http://papers.nips.cc/paper_files/paper/2022/hash/0f94c552e5fe82bc152494985e34bd48-Abstract-Conference.html)]
 - [[[15]. Open-Ended <font color='black'>*Reinforcement Learning*</font> with Neural Reward Functions.](http://papers.nips.cc/paper_files/paper/2022/hash/10a6bdcabbd5a3d36b760daa295f63c1-Abstract-Conference.html)]
 - [[[16]. Towards Safe <font color='black'>*Reinforcement Learning*</font> with a Safety Editor Policy.](http://papers.nips.cc/paper_files/paper/2022/hash/11afefdd848d1bc9ac9f1604d9f45817-Abstract-Conference.html)]
 - [[[17]. Sustainable Online <font color='black'>*Reinforcement Learning*</font> for Auto-bidding.](http://papers.nips.cc/paper_files/paper/2022/hash/11faf17bf7e5412d9cded369f97db23d-Abstract-Conference.html)]
 - [[[18]. Enhanced Meta <font color='black'>*Reinforcement Learning*</font> via Demonstrations in Sparse Reward Environments.](http://papers.nips.cc/paper_files/paper/2022/hash/122f45f4d451617ac87adf7024ee14cd-Abstract-Conference.html)]
 - [[[19]. Bellman Residual Orthogonalization for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/14ecbfb2216bab76195b60bfac7efb1f-Abstract-Conference.html)]
 - [[[20]. Online <font color='black'>*Reinforcement Learning*</font> for Mixed Policy Scopes.](http://papers.nips.cc/paper_files/paper/2022/hash/15349e1c554406b7719d047a498e7117-Abstract-Conference.html)]
 - [[[21]. <font color='black'>*Reinforcement Learning*</font> with Non-Exponential Discounting.](http://papers.nips.cc/paper_files/paper/2022/hash/178b306c7ee66a66db2171646e17da36-Abstract-Conference.html)]
 - [[[22]. Discrete Compositional Representations as an Abstraction for Goal Conditioned <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/18ddfb199d71a8a24f83abc1ced077b7-Abstract-Conference.html)]
 - [[[23]. A Policy-Guided Imitation Approach for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/1a0755b249b772ed5529796b0a7cc9bd-Abstract-Conference.html)]
 - [[[24]. Asynchronous Actor-Critic for Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/1c153788756d35559c22d105d1182c30-Abstract-Conference.html)]
 - [[[25]. Challenging Common Assumptions in Convex <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/1cb5b3d64bdf3c6642c8d9a8fbecd019-Abstract-Conference.html)]
 - [[[26]. Constrained GPI for Zero-Shot Transfer in <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/1d8dc55c1f6cf124af840ce1d92d1896-Abstract-Conference.html)]
 - [[[27]. Understanding Deep Neural Function Approximation in <font color='black'>*Reinforcement Learning*</font> via $\epsilon$-Greedy Exploration.](http://papers.nips.cc/paper_files/paper/2022/hash/2119b5ac365c30dfac17a840c2755c30-Abstract-Conference.html)]
 - [[[28]. Towards Human-Level Bimanual Dexterous Manipulation with <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/217a2a387f52c30755c37b0a73430291-Abstract-Datasets_and_Benchmarks.html)]
 - [[[29]. ResQ: A Residual Q Function-based Approach for Multi-Agent <font color='black'>*Reinforcement Learning*</font> Value Factorization.](http://papers.nips.cc/paper_files/paper/2022/hash/2456a42386e445ba884511aa17ca4a30-Abstract-Conference.html)]
 - [[[30]. Self-Organized Group for Cooperative Multi-agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/25b040c97a75021e57100648a20b1e10-Abstract-Conference.html)]
 - [[[31]. Exploration-Guided Reward Shaping for <font color='black'>*Reinforcement Learning*</font> under Sparse Rewards.](http://papers.nips.cc/paper_files/paper/2022/hash/266c0f191b04cbbbe529016d0edc847e-Abstract-Conference.html)]
 - [[[32]. Active Exploration for Inverse <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/26d01e5ed42d8dcedd6aa0e3e99cffc4-Abstract-Conference.html)]
 - [[[33]. Disentangling Transfer in Continual <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/2938ad0434a6506b125d8adaff084a4a-Abstract-Conference.html)]
 - [[[34]. Quantile Constrained <font color='black'>*Reinforcement Learning*</font>: A <font color='black'>*Reinforcement Learning*</font> Framework Constraining Outage Probability.](http://papers.nips.cc/paper_files/paper/2022/hash/2a07348a6a7b2c208ab5cb1ee0e78ab5-Abstract-Conference.html)]
 - [[[35]. Grounded <font color='black'>*Reinforcement Learning*</font>: Learning to Win the Game under Human Commands.](http://papers.nips.cc/paper_files/paper/2022/hash/318f3ae8be3c97cb7555e1c932f472a1-Abstract-Conference.html)]
 - [[[36]. CEIP: Combining Explicit and Implicit Priors for <font color='black'>*Reinforcement Learning*</font> with Demonstrations.](http://papers.nips.cc/paper_files/paper/2022/hash/322e4a595afd9442a89f0bfaa441871e-Abstract-Conference.html)]
 - [[[37]. Meta-<font color='black'>*Reinforcement Learning*</font> with Self-Modifying Networks.](http://papers.nips.cc/paper_files/paper/2022/hash/332b4fbe322e11a71fa39d91c664d8fa-Abstract-Conference.html)]
 - [[[38]. Near Instance-Optimal PAC <font color='black'>*Reinforcement Learning*</font> for Deterministic MDPs.](http://papers.nips.cc/paper_files/paper/2022/hash/39c60dda48ebf0a2e5dda52ce08eb5c8-Abstract-Conference.html)]
 - [[[39]. Deciding What to Model: Value-Equivalent Sampling for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html)]
 - [[[40]. A Deep <font color='black'>*Reinforcement Learning*</font> Framework for Column Generation.](http://papers.nips.cc/paper_files/paper/2022/hash/3ecfe5c632afb7d96a2337b18ff99b1f-Abstract-Conference.html)]
 - [[[41]. Maximum-Likelihood Inverse <font color='black'>*Reinforcement Learning*</font> with Finite-Time Guarantees.](http://papers.nips.cc/paper_files/paper/2022/hash/41bd71e7bf7f9fe68f1c936940fd06bd-Abstract-Conference.html)]
 - [[[42]. A Unified Diversity Measure for Multiagent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/435cce71b4007699041dfffa4f034079-Abstract-Conference.html)]
 - [[[43]. Curriculum <font color='black'>*Reinforcement Learning*</font> using Optimal Transport via Gradual Domain Adaptation.](http://papers.nips.cc/paper_files/paper/2022/hash/4556f5398bd2c61bd7500e306b4e560a-Abstract-Conference.html)]
 - [[[44]. Optimistic Posterior Sampling for <font color='black'>*Reinforcement Learning*</font> with Few Samples and Tight Guarantees.](http://papers.nips.cc/paper_files/paper/2022/hash/45e15bae91a6f213d45e203b8a29be48-Abstract-Conference.html)]
 - [[[45]. Understanding the Evolution of Linear Regions in Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/4685275b9a6a2c55d78135563dfd50bb-Abstract-Conference.html)]
 - [[[46]. Provably Feedback-Efficient <font color='black'>*Reinforcement Learning*</font> via Active Reward Learning.](http://papers.nips.cc/paper_files/paper/2022/hash/476c289f685e27936aa089e9d53a4213-Abstract-Conference.html)]
 - [[[47]. Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/49be51578b507f37cd8b5fad379af183-Abstract-Conference.html)]
 - [[[48]. S2P: State-conditioned Image Synthesis for Data Augmentation in Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/4b32c2943a02331792877cc6b5205f49-Abstract-Conference.html)]
 - [[[49]. Provably Efficient Offline Multi-agent <font color='black'>*Reinforcement Learning*</font> via Strategy-wise Bonus.](http://papers.nips.cc/paper_files/paper/2022/hash/4cca5640267b416cef4f00630aef93a2-Abstract-Conference.html)]
 - [[[50]. Honor of Kings Arena: an Environment for Generalization in Competitive <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/4dbb61cb68671edc4ca3712d70083b9f-Abstract-Datasets_and_Benchmarks.html)]
 - [[[51]. Value Function Decomposition for Iterative Design of <font color='black'>*Reinforcement Learning*</font> Agents.](http://papers.nips.cc/paper_files/paper/2022/hash/4eb2c0adafbe71269f3a772c130f9e53-Abstract-Conference.html)]
 - [[[52]. E-MAPP: Efficient Multi-Agent <font color='black'>*Reinforcement Learning*</font> with Parallel Program Guidance.](http://papers.nips.cc/paper_files/paper/2022/hash/4f2accafe6fa355624f3ee42207cc7b8-Abstract-Conference.html)]
 - [[[53]. Distributional Reward Estimation for Effective Multi-agent Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/520425a5a4c2fb7f7fc345078b188201-Abstract-Conference.html)]
 - [[[54]. Pre-Trained Image Encoder for Generalizable Visual <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/548a482d4496ce109cddfbeae5defa7d-Abstract-Conference.html)]
 - [[[55]. Shield Decentralization for Safe Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/57444e14ecd9e2c8f603b4f012ce3811-Abstract-Conference.html)]
 - [[[56]. Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/57fbe68cb318cad62c4ae4c91c83cba3-Abstract-Conference.html)]
 - [[[57]. Meta <font color='black'>*Reinforcement Learning*</font> with Finite Training Tasks - a Density Estimation Approach.](http://papers.nips.cc/paper_files/paper/2022/hash/5833b4daf5b076dd1cdb362b163dff0c-Abstract-Conference.html)]
 - [[[58]. DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/58b286aea34a91a3d33e58af0586fa40-Abstract-Conference.html)]
 - [[[59]. Bayesian Optimistic Optimization: Optimistic Exploration for Model-based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/5bcb807ae43ad0851a6ba6162a866404-Abstract-Conference.html)]
 - [[[60]. <font color='black'>*Reinforcement Learning*</font> in a Birth and Death Process: Breaking the Dependence on the State Space.](http://papers.nips.cc/paper_files/paper/2022/hash/5d2781cc34f459618a9a504761043055-Abstract-Conference.html)]
 - [[[61]. Provable Defense against Backdoor Policies in <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/5e67e6a814526079ad8505bf6d926fb6-Abstract-Conference.html)]
 - [[[62]. You Only Live Once: Single-Life <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/5ec4e93f2cec19d47ef852a0e1fb2c48-Abstract-Conference.html)]
 - [[[63]. Data-Efficient Pipeline for Offline <font color='black'>*Reinforcement Learning*</font> with Limited Data.](http://papers.nips.cc/paper_files/paper/2022/hash/5ee7ed60a7e8169012224dec5fe0d27f-Abstract-Conference.html)]
 - [[[64]. On Gap-dependent Bounds for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/5f5f7b6080dcadced61cf5d96f7c6dde-Abstract-Conference.html)]
 - [[[65]. GriddlyJS: A Web IDE for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/611b896d447df43c898062358df4c114-Abstract-Datasets_and_Benchmarks.html)]
 - [[[66]. Learning to Share in Networked Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/61d8577984e4ef0cba20966eb3ef2ed8-Abstract-Conference.html)]
 - [[[67]. Efficient Meta <font color='black'>*Reinforcement Learning*</font> for Preference-based Fast Adaptation.](http://papers.nips.cc/paper_files/paper/2022/hash/63b2b056f48653b7cff0d8d233c96a4d-Abstract-Conference.html)]
 - [[[68]. PAC: Assisted Value Factorization with Counterfactual Predictions in Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/65338cfb603d4871a2c38e53a3e039c9-Abstract-Conference.html)]
 - [[[69]. Plan To Predict: Learning an Uncertainty-Foreseeing Model For Model-Based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/65beb73449888fabcf601b3a3ef4b3a7-Abstract-Conference.html)]
 - [[[70]. RAMBO-RL: Robust Adversarial Model-Based Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/6691c5e4a199b72dffd9c90acb63bcd6-Abstract-Conference.html)]
 - [[[71]. Inherently Explainable <font color='black'>*Reinforcement Learning*</font> in Natural Language.](http://papers.nips.cc/paper_files/paper/2022/hash/672e44a114a41d5f34b97459877c083d-Abstract-Conference.html)]
 - [[[72]. On <font color='black'>*Reinforcement Learning*</font> and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting.](http://papers.nips.cc/paper_files/paper/2022/hash/67496dfa96afddab795530cc7c69b57a-Abstract-Conference.html)]
 - [[[73]. Multi-Agent <font color='black'>*Reinforcement Learning*</font> is a Sequence Modeling Problem.](http://papers.nips.cc/paper_files/paper/2022/hash/69413f87e5a34897cd010ca698097d0a-Abstract-Conference.html)]
 - [[[74]. When to Ask for Help: Proactive Interventions in Autonomous <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/6bf82cc56a5fa0287c438baa8be65a70-Abstract-Conference.html)]
 - [[[75]. <font color='black'>*Reinforcement Learning*</font> with Neural Radiance Fields.](http://papers.nips.cc/paper_files/paper/2022/hash/6c294f059e3d77d58dbb8fe48f21fe00-Abstract-Conference.html)]
 - [[[76]. Sample-Efficient <font color='black'>*Reinforcement Learning*</font> of Partially Observable Markov Games.](http://papers.nips.cc/paper_files/paper/2022/hash/743459dae9b2c5d2904e5432d5298128-Abstract-Conference.html)]
 - [[[77]. DeepFoids: Adaptive Bio-Inspired Fish Simulation with Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/74fa9e6bc36aa567fe7cf002b733a30d-Abstract-Conference.html)]
 - [[[78]. Influencing Long-Term Behavior in Multiagent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/7749f9c0d5ff109231be21e910a3ced2-Abstract-Conference.html)]
 - [[[79]. Uncertainty Estimation Using Riemannian Model Dynamics for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/78e36c70d5051e9e271b00289624d709-Abstract-Conference.html)]
 - [[[80]. Low-Rank Modular <font color='black'>*Reinforcement Learning*</font> via Muscle Synergy.](http://papers.nips.cc/paper_files/paper/2022/hash/7da6005a8d6942e8b328357da2872aed-Abstract-Conference.html)]
 - [[[81]. GALOIS: Boosting Deep <font color='black'>*Reinforcement Learning*</font> via Generalizable Logic Synthesis.](http://papers.nips.cc/paper_files/paper/2022/hash/7dd309df03d37643b96f5048b44da798-Abstract-Conference.html)]
 - [[[82]. Faster Deep <font color='black'>*Reinforcement Learning*</font> with Slower Online Network.](http://papers.nips.cc/paper_files/paper/2022/hash/7dfa77fcef807c9a078b58fd619ad897-Abstract-Conference.html)]
 - [[[83]. Learn to Match with No Regret: <font color='black'>*Reinforcement Learning*</font> in Markov Matching Markets.](http://papers.nips.cc/paper_files/paper/2022/hash/7e0af0d1bc0ec2a90fc294be2e00447e-Abstract-Conference.html)]
 - [[[84]. Causality-driven Hierarchical Structure Discovery for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/7e9fbd01b3084956dd8a070c7bf30bad-Abstract-Conference.html)]
 - [[[85]. Large-Scale Retrieval for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/7eca17ef54789b0663cab421f2e9dbf5-Abstract-Conference.html)]
 - [[[86]. Uncertainty-Aware <font color='black'>*Reinforcement Learning*</font> for Risk-Sensitive Player Evaluation in Sports Game.](http://papers.nips.cc/paper_files/paper/2022/hash/7f6e51d8298aa01b084b700ab91aff94-Abstract-Conference.html)]
 - [[[87]. Spectrum Random Masking for Generalization in Image-based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/802a4350ca4fced76b13b8b320af1543-Abstract-Conference.html)]
 - [[[88]. SPD: Synergy Pattern Diversifying Oriented Unsupervised Multi-agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/825341ab91db01bf063add41ac022702-Abstract-Conference.html)]
 - [[[89]. CodeRL: Mastering Code Generation through Pretrained Models and Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/8636419dea1aa9fbd25fc4248e702da4-Abstract-Conference.html)]
 - [[[90]. PaCo: Parameter-Compositional Multi-task <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/86b8ad667206fb9a52ae575fbf1cd6be-Abstract-Conference.html)]
 - [[[91]. Meta-Reward-Net: Implicitly Differentiable Reward Learning for Preference-based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html)]
 - [[[92]. EnvPool: A Highly Parallel <font color='black'>*Reinforcement Learning*</font> Environment Execution Engine.](http://papers.nips.cc/paper_files/paper/2022/hash/8caaf08e49ddbad6694fae067442ee21-Abstract-Datasets_and_Benchmarks.html)]
 - [[[93]. Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/8d6b1d775014eff18256abeb207202ad-Abstract-Conference.html)]
 - [[[94]. When to Update Your Model: Constrained Model-based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/927eae0f3d1c89cc39398022f436c472-Abstract-Conference.html)]
 - [[[95]. RORL: Robust Offline <font color='black'>*Reinforcement Learning*</font> via Conservative Smoothing.](http://papers.nips.cc/paper_files/paper/2022/hash/96bbdd0ed2a9e7cd2fb7caf2fae15f3d-Abstract-Conference.html)]
 - [[[96]. The Impact of Task Underspecification in Evaluating Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/96ca792fddef7c1e3366c405022463cb-Abstract-Conference.html)]
 - [[[97]. Model-based Safe Deep <font color='black'>*Reinforcement Learning*</font> via a Constrained Proximal Policy Optimization Algorithm.](http://papers.nips.cc/paper_files/paper/2022/hash/9a8eb202c060b7d81f5889631cbcd47e-Abstract-Conference.html)]
 - [[[98]. Towards Trustworthy Automatic Diagnosis Systems by Emulating Doctors' Reasoning with Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/9b6c8c4a5aeb6a37c9efa963e30993d9-Abstract-Conference.html)]
 - [[[99]. Near-Optimal Regret Bounds for Multi-batch <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/9bcd1fa0c05e5f25ba7a1261f1852e82-Abstract-Conference.html)]
 - [[[100]. NeoRL: A Near Real-World Benchmark for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/9cd828eb8dc81a84fb6bf89a94263e1b-Abstract-Datasets_and_Benchmarks.html)]
 - [[[101]. Improving Zero-Shot Generalization in Offline <font color='black'>*Reinforcement Learning*</font> using Generalized Similarity Functions.](http://papers.nips.cc/paper_files/paper/2022/hash/9fbdfded5c4d2969d889efc72f85c644-Abstract-Conference.html)]
 - [[[102]. Mask-based Latent Reconstruction for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/a0709efe5139939ab69902884ecad9c1-Abstract-Conference.html)]
 - [[[103]. Conservative Dual Policy Optimization for Efficient Model-Based <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/a3769fddee1b20552d2490c4ff18b136-Abstract-Conference.html)]
 - [[[104]. Distributionally Adaptive Meta <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/a60c43ba078b723d3d517d28c50ded4c-Abstract-Conference.html)]
 - [[[105]. TTOpt: A Maximum Volume Quantized Tensor Train-based Optimization and its Application to <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/a730abbcd6cf4a371ca9545db5922442-Abstract-Conference.html)]
 - [[[106]. A Mixture Of Surprises for Unsupervised <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/a7667ee5d545a43d2f0fda98863c260e-Abstract-Conference.html)]
 - [[[107]. Generalizing Goal-Conditioned <font color='black'>*Reinforcement Learning*</font> with Variational Causal Reasoning.](http://papers.nips.cc/paper_files/paper/2022/hash/a96368eb38bce0956a1132154d70d72d-Abstract-Conference.html)]
 - [[[108]. ProtoX: Explaining a <font color='black'>*Reinforcement Learning*</font> Agent via Prototyping.](http://papers.nips.cc/paper_files/paper/2022/hash/ae5bf4f35236240c9460e761c60fa53d-Abstract-Conference.html)]
 - [[[109]. DOMINO: Decomposed Mutual Information Optimization for Generalized Context in Meta-<font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/b0b1cfc8ede53f452cabf8b9cf4eef76-Abstract-Conference.html)]
 - [[[110]. MATE: Benchmarking Multi-Agent <font color='black'>*Reinforcement Learning*</font> in Distributed Target Coverage Control.](http://papers.nips.cc/paper_files/paper/2022/hash/b2a1c152f14a4b842a9ddb3bd84c62a1-Abstract-Datasets_and_Benchmarks.html)]
 - [[[111]. Receding Horizon Inverse <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/b2b781badeeb49896c4b324c466ec442-Abstract-Conference.html)]
 - [[[112]. Oracle Inequalities for Model Selection in Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/b51693c2ba5b5ddf67429966576fb962-Abstract-Conference.html)]
 - [[[113]. Exponential Family Model-Based <font color='black'>*Reinforcement Learning*</font> via Score Matching.](http://papers.nips.cc/paper_files/paper/2022/hash/b693a240cf1009bff9fa4422141c9392-Abstract-Conference.html)]
 - [[[114]. Regret Bounds for Information-Directed <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/b733cdd80ed2ae7e3156d8c33108c5d5-Abstract-Conference.html)]
 - [[[115]. Reincarnating <font color='black'>*Reinforcement Learning*</font>: Reusing Prior Computation to Accelerate Progress.](http://papers.nips.cc/paper_files/paper/2022/hash/ba1c5356d9164bb64c446a4b690226b0-Abstract-Conference.html)]
 - [[[116]. Dynamic Inverse <font color='black'>*Reinforcement Learning*</font> for Characterizing Animal Behavior.](http://papers.nips.cc/paper_files/paper/2022/hash/bf215fa7fe70a38c5e967e59c44a99d0-Abstract-Conference.html)]
 - [[[117]. Robust Imitation via Mirror Descent Inverse <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/c1f7b1ed763e9c75e4db74b49b76db5f-Abstract-Conference.html)]
 - [[[118]. The Nature of Temporal Difference Errors in Multi-step Distributional <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/c32de883c5fe94d33a20a717fad53971-Abstract-Conference.html)]
 - [[[119]. On the Effect of Pre-training for Transformer in Different Modality on Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/c5eddf0069fe150ac2c768e2969e38d1-Abstract-Conference.html)]
 - [[[120]. Look where you look! Saliency-guided Q-networks for generalization in visual <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/c5ee2a08fbe743b171b0b4b2bdfd6f86-Abstract-Conference.html)]
 - [[[121]. Does Self-supervised Learning Really Improve <font color='black'>*Reinforcement Learning*</font> from Pixels?](http://papers.nips.cc/paper_files/paper/2022/hash/c75abb33341363ee874a71f81dc45a3a-Abstract-Conference.html)]
 - [[[122]. Distributional <font color='black'>*Reinforcement Learning*</font> for Risk-Sensitive Policies.](http://papers.nips.cc/paper_files/paper/2022/hash/c88a2bd0e793550d0e885aa6e31ca277-Abstract-Conference.html)]
 - [[[123]. A Theoretical Understanding of Gradient Bias in Meta-<font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/c8f9db5b83fac60ca3c6d6d06a9adcd6-Abstract-Conference.html)]
 - [[[124]. Supported Policy Optimization for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/caa934a507a952698d54efb24845fc4b-Abstract-Conference.html)]
 - [[[125]. Provable Benefit of Multitask Representation Learning in <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/cde328b7bf6358f5ebb91fe9c539745e-Abstract-Conference.html)]
 - [[[126]. Modeling Human Exploration Through Resource-Rational <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/cde542f47c67907e170a1e1a7b32f6ad-Abstract-Conference.html)]
 - [[[127]. Factored Adaptation for Non-Stationary <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/cf4356f994917177213c55ff438ddf71-Abstract-Conference.html)]
 - [[[128]. Robust <font color='black'>*Reinforcement Learning*</font> using Offline Data.](http://papers.nips.cc/paper_files/paper/2022/hash/d01bda31bbcd780774ff15b534e03c40-Abstract-Conference.html)]
 - [[[129]. Model-based Lifelong <font color='black'>*Reinforcement Learning*</font> with Bayesian Exploration.](http://papers.nips.cc/paper_files/paper/2022/hash/d0cf89927acd9136d27ebf08f9e8a888-Abstract-Conference.html)]
 - [[[130]. Rethinking Individual Global Max in Cooperative Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/d112fdd31c830900d1f2e4ccebffb54f-Abstract-Conference.html)]
 - [[[131]. Efficient Risk-Averse <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/d2511dfb731fa336739782ba825cd98c-Abstract-Conference.html)]
 - [[[132]. VRL3: A Data-Driven Framework for Visual Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/d4cc7a2d0d70736e29a3b48c3729bc06-Abstract-Conference.html)]
 - [[[133]. Efficient Scheduling of Data Augmentation for Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/d74d002a9154b4cc433a234feb27c5f4-Abstract-Conference.html)]
 - [[[134]. Distributed Inverse Constrained <font color='black'>*Reinforcement Learning*</font> for Multi-agent Systems.](http://papers.nips.cc/paper_files/paper/2022/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html)]
 - [[[135]. Universally Expressive Communication in Multi-Agent <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/d8a19c815a8bef25e6094e87f963d28e-Abstract-Conference.html)]
 - [[[136]. A Boosting Approach to <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/daf8364f0715a41a469c677c0adc4754-Abstract-Conference.html)]
 - [[[137]. Near-Optimal Goal-Oriented <font color='black'>*Reinforcement Learning*</font> in Non-Stationary Environments.](http://papers.nips.cc/paper_files/paper/2022/hash/dbb5180957513805ebeea787b8c66ac9-Abstract-Conference.html)]
 - [[[138]. Explainable <font color='black'>*Reinforcement Learning*</font> via Model Transforms.](http://papers.nips.cc/paper_files/paper/2022/hash/dbef234be68d8b170240511639610fd1-Abstract-Conference.html)]
 - [[[139]. Leveraging Factored Action Spaces for Efficient Offline <font color='black'>*Reinforcement Learning*</font> in Healthcare.](http://papers.nips.cc/paper_files/paper/2022/hash/dda7f9378a210c25e470e19304cce85d-Abstract-Conference.html)]
 - [[[140]. Unsupervised <font color='black'>*Reinforcement Learning*</font> with Contrastive Intrinsic Control.](http://papers.nips.cc/paper_files/paper/2022/hash/debf482a7dbdc401f9052dbe15702837-Abstract-Conference.html)]
 - [[[141]. Bootstrapped Transformer for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/e0ccda3cb17b084a6f43c62cfac4784b-Abstract-Conference.html)]
 - [[[142]. Rethinking Value Function Learning for Generalization in <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/e19ab2dde2e60cf68d1ded18c38938f4-Abstract-Conference.html)]
 - [[[143]. Transformer-based Working Memory for Multiagent <font color='black'>*Reinforcement Learning*</font> with Action Parsing.](http://papers.nips.cc/paper_files/paper/2022/hash/e1cf57f1e104c6c05e31894c15a65e99-Abstract-Conference.html)]
 - [[[144]. Learning to Attack Federated Learning: A Model-based <font color='black'>*Reinforcement Learning*</font> Attack Framework.](http://papers.nips.cc/paper_files/paper/2022/hash/e2ef0cae667dbe9bfdbcaed1bd91807b-Abstract-Conference.html)]
 - [[[145]. Recursive <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/e6f8759254d86ea9c197d30b92b313ca-Abstract-Conference.html)]
 - [[[146]. Contrastive Learning as Goal-Conditioned <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/e7663e974c4ee7a2b475a4775201ce1f-Abstract-Conference.html)]
 - [[[147]. <font color='black'>*Reinforcement Learning*</font> with a Terminator.](http://papers.nips.cc/paper_files/paper/2022/hash/e83b86156555ab9692743f9f8f67adf1-Abstract-Conference.html)]
 - [[[148]. <font color='black'>*Reinforcement Learning*</font> with Logarithmic Regret and Policy Switches.](http://papers.nips.cc/paper_files/paper/2022/hash/ea318cbc405c9803925e188e5d6836c6-Abstract-Conference.html)]
 - [[[149]. Regret Bounds for Risk-Sensitive <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/eb4898d622e9a48b5f9713ea1fcff2bf-Abstract-Conference.html)]
 - [[[150]. Computationally Efficient Horizon-Free <font color='black'>*Reinforcement Learning*</font> for Linear Mixture MDPs.](http://papers.nips.cc/paper_files/paper/2022/hash/ebba182cb97864368fdb6ae00773a5e4-Abstract-Conference.html)]
 - [[[151]. Object-Category Aware <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/ec3d49763c653ad7c8d587f52220c129-Abstract-Conference.html)]
 - [[[152]. When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html)]
 - [[[153]. Learning Representations via a Robust Behavioral Metric for Deep <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/eda9523faa5e7191aee1c2eaff669716-Abstract-Conference.html)]
 - [[[154]. LAPO: Latent-Variable Advantage-Weighted Policy Optimization for Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/efb2072a358cefb75886a315a6fcf880-Abstract-Conference.html)]
 - [[[155]. Robust On-Policy Sampling for Data-Efficient Policy Evaluation in <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/f2dbede0879b9d04ceb30f1b8b476b27-Abstract-Conference.html)]
 - [[[156]. Skills Regularized Task Decomposition for Multi-task Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/f376f5dff6f6ec6364aea7a46ab49574-Abstract-Conference.html)]
 - [[[157]. ASPiRe: Adaptive Skill Priors for <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/fbd8e65962da06f83f3f28b52774ffd0-Abstract-Conference.html)]
 - [[[158]. DASCO: Dual-Generator Adversarial Support Constrained Offline <font color='black'>*Reinforcement Learning*</font>.](http://papers.nips.cc/paper_files/paper/2022/hash/fe51de4e7baf52e743b679e3bdba7905-Abstract-Conference.html)]
