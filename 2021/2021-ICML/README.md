# 2021-ICML Accepted Papers

 - [[1]. Safe Reinforcement Learning with Linear Function Approximation.](http://proceedings.mlr.press/v139/amani21a.html)
 - [[2]. Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarantees.](http://proceedings.mlr.press/v139/badrinath21a.html)
 - [[3]. Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half Precision.](http://proceedings.mlr.press/v139/bjorck21a.html)
 - [[4]. Reinforcement Learning of Implicit and Explicit Control Flow Instructions.](http://proceedings.mlr.press/v139/brooks21a.html)
 - [[5]. Learning Routines for Effective Off-Policy Reinforcement Learning.](http://proceedings.mlr.press/v139/cetin21a.html)
 - [[6]. Goal-Conditioned Reinforcement Learning with Imagined Subgoals.](http://proceedings.mlr.press/v139/chane-sane21a.html)
 - [[7]. Modularity in Reinforcement Learning via Algorithmic Independence in Credit Assignment.](http://proceedings.mlr.press/v139/chang21b.html)
 - [[8]. Solving Challenging Dexterous Manipulation Tasks With Trajectory Optimisation and Reinforcement Learning.](http://proceedings.mlr.press/v139/charlesworth21a.html)
 - [[9]. Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills.](http://proceedings.mlr.press/v139/chebotar21a.html)
 - [[10]. Improved Corruption Robust Algorithms for Episodic Reinforcement Learning.](http://proceedings.mlr.press/v139/chen21d.html)
 - [[11]. Variational Empowerment as Representation Learning for Goal-Conditioned Reinforcement Learning.](http://proceedings.mlr.press/v139/choi21b.html)
 - [[12]. Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing.](http://proceedings.mlr.press/v139/christianos21a.html)
 - [[13]. Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/curi21a.html)
 - [[14]. Offline Reinforcement Learning with Pseudometric Learning.](http://proceedings.mlr.press/v139/dadashi21a.html)
 - [[15]. Demonstration-Conditioned Reinforcement Learning for Few-Shot Imitation.](http://proceedings.mlr.press/v139/dance21a.html)
 - [[16]. SAINT-ACC: Safety-Aware Intelligent Adaptive Cruise Control for Autonomous Vehicles Using Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/das21a.html)
 - [[17]. Kernel-Based Reinforcement Learning: A Finite-Time Analysis.](http://proceedings.mlr.press/v139/domingues21a.html)
 - [[18]. Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning.](http://proceedings.mlr.press/v139/duan21a.html)
 - [[19]. Reinforcement Learning Under Moral Uncertainty.](http://proceedings.mlr.press/v139/ecoffet21a.html)
 - [[20]. Self-Paced Context Evaluation for Contextual Reinforcement Learning.](http://proceedings.mlr.press/v139/eimer21a.html)
 - [[21]. Model-based Reinforcement Learning for Continuous Control with Posterior Sampling.](http://proceedings.mlr.press/v139/fan21b.html)
 - [[22]. Risk-Sensitive Reinforcement Learning with Function Approximation: A Debiasing Approach.](http://proceedings.mlr.press/v139/fei21a.html)
 - [[23]. PsiPhi-Learning: Reinforcement Learning with Demonstrations using Successor Features and Inverse Temporal Difference Learning.](http://proceedings.mlr.press/v139/filos21a.html)
 - [[24]. A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation.](http://proceedings.mlr.press/v139/fujimoto21a.html)
 - [[25]. Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/furuta21a.html)
 - [[26]. Spectral Normalisation for Deep Reinforcement Learning: An Optimisation Perspective.](http://proceedings.mlr.press/v139/gogianu21a.html)
 - [[27]. Detecting Rewards Deterioration in Episodic Reinforcement Learning.](http://proceedings.mlr.press/v139/greenberg21a.html)
 - [[28]. UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/gupta21a.html)
 - [[29]. Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning.](http://proceedings.mlr.press/v139/hanjie21a.html)
 - [[30]. Sparse Feature Selection Makes Batch Reinforcement Learning More Sample Efficient.](http://proceedings.mlr.press/v139/hao21a.html)
 - [[31]. Logarithmic Regret for Reinforcement Learning with Linear Function Approximation.](http://proceedings.mlr.press/v139/he21c.html)
 - [[32]. Generalizable Episodic Memory for Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/hu21d.html)
 - [[33]. Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/iqbal21a.html)
 - [[34]. Randomized Exploration in Reinforcement Learning with General Value Function Approximation.](http://proceedings.mlr.press/v139/ishfaq21a.html)
 - [[35]. Emphatic Algorithms for Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/jiang21j.html)
 - [[36]. Efficient Performance Bounds for Primal-Dual Reinforcement Learning from Demonstrations.](http://proceedings.mlr.press/v139/kamoutsi21a.html)
 - [[37]. Reward Identification in Inverse Reinforcement Learning.](http://proceedings.mlr.press/v139/kim21c.html)
 - [[38]. A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning.](http://proceedings.mlr.press/v139/kim21g.html)
 - [[39]. A Lower Bound for the Sample Complexity of Inverse Reinforcement Learning.](http://proceedings.mlr.press/v139/komanduru21a.html)
 - [[40]. High Confidence Generalization for Reinforcement Learning.](http://proceedings.mlr.press/v139/kostas21a.html)
 - [[41]. Offline Reinforcement Learning with Fisher Divergence Critic Regularization.](http://proceedings.mlr.press/v139/kostrikov21a.html)
 - [[42]. Revisiting Peng's Q(Î») for Modern Reinforcement Learning.](http://proceedings.mlr.press/v139/kozuno21a.html)
 - [[43]. SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/lee21g.html)
 - [[44]. PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training.](http://proceedings.mlr.press/v139/lee21i.html)
 - [[45]. Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot.](http://proceedings.mlr.press/v139/leibo21a.html)
 - [[46]. MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning.](http://proceedings.mlr.press/v139/li21g.html)
 - [[47]. Parallel Droplet Control in MEDA Biochips using Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/liang21c.html)
 - [[48]. Cooperative Exploration for Multi-Agent Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/liu21j.html)
 - [[49]. Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition.](http://proceedings.mlr.press/v139/liu21m.html)
 - [[50]. Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices.](http://proceedings.mlr.press/v139/liu21s.html)
 - [[51]. A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.](http://proceedings.mlr.press/v139/liu21z.html)
 - [[52]. Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/mahajan21a.html)
 - [[53]. Inverse Constrained Reinforcement Learning.](http://proceedings.mlr.press/v139/malik21a.html)
 - [[54]. Sample Efficient Reinforcement Learning In Continuous State Spaces: A Perspective Beyond Linearity.](http://proceedings.mlr.press/v139/malik21c.html)
 - [[55]. Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic MDPs.](http://proceedings.mlr.press/v139/mao21b.html)
 - [[56]. Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks.](http://proceedings.mlr.press/v139/meirom21a.html)
 - [[57]. Counterfactual Credit Assignment in Model-Free Reinforcement Learning.](http://proceedings.mlr.press/v139/mesnard21a.html)
 - [[58]. Offline Meta-Reinforcement Learning with Advantage Weighting.](http://proceedings.mlr.press/v139/mitchell21a.html)
 - [[59]. Emergent Social Learning via Multi-agent Reinforcement Learning.](http://proceedings.mlr.press/v139/ndousse21a.html)
 - [[60]. Density Constrained Reinforcement Learning.](http://proceedings.mlr.press/v139/qin21a.html)
 - [[61]. Decoupling Value and Policy for Generalization in Reinforcement Learning.](http://proceedings.mlr.press/v139/raileanu21a.html)
 - [[62]. Model-Based Reinforcement Learning via Latent-Space Collocation.](http://proceedings.mlr.press/v139/rybkin21b.html)
 - [[63]. Recomposing the Reinforcement Learning Building Blocks with Hypernetworks.](http://proceedings.mlr.press/v139/sarafian21a.html)
 - [[64]. RRL: Resnet as representation for Reinforcement Learning.](http://proceedings.mlr.press/v139/shah21a.html)
 - [[65]. Structured World Belief for Reinforcement Learning in POMDP.](http://proceedings.mlr.press/v139/singh21a.html)
 - [[66]. Multi-Task Reinforcement Learning with Context-based Representations.](http://proceedings.mlr.press/v139/sodhani21a.html)
 - [[67]. Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks.](http://proceedings.mlr.press/v139/sohn21a.html)
 - [[68]. PC-MLP: Model-based Reinforcement Learning with Policy Cover Guided Exploration.](http://proceedings.mlr.press/v139/song21b.html)
 - [[69]. Decoupling Representation Learning from Reinforcement Learning.](http://proceedings.mlr.press/v139/stooke21a.html)
 - [[70]. Reinforcement Learning for Cost-Aware Markov Decision Processes.](http://proceedings.mlr.press/v139/suttle21a.html)
 - [[71]. REPAINT: Knowledge Transfer in Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/tao21a.html)
 - [[72]. Safe Reinforcement Learning Using Advantage-Based Intervention.](http://proceedings.mlr.press/v139/wagener21a.html)
 - [[73]. Towards Better Laplacian Representation in Reinforcement Learning with Generalized Graph Drawing.](http://proceedings.mlr.press/v139/wang21ae.html)
 - [[74]. On Reinforcement Learning with Adversarial Corruption and Its Application to Block MDP.](http://proceedings.mlr.press/v139/wu21g.html)
 - [[75]. Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning.](http://proceedings.mlr.press/v139/wu21i.html)
 - [[76]. Deep Reinforcement Learning amidst Continual Structured Non-Stationarity.](http://proceedings.mlr.press/v139/xie21c.html)
 - [[77]. CRPO: A New Approach for Safe Reinforcement Learning with Convergence Guarantee.](http://proceedings.mlr.press/v139/xu21a.html)
 - [[78]. Accelerating Safe Reinforcement Learning with Constraint-mismatched Baseline Policies.](http://proceedings.mlr.press/v139/yang21i.html)
 - [[79]. Reinforcement Learning with Prototypical Representations.](http://proceedings.mlr.press/v139/yarats21a.html)
 - [[80]. Continuous-time Model-based Reinforcement Learning.](http://proceedings.mlr.press/v139/yildiz21a.html)
 - [[81]. Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL.](http://proceedings.mlr.press/v139/zanette21a.html)
 - [[82]. DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning.](http://proceedings.mlr.press/v139/zha21a.html)
 - [[83]. Near Optimal Reward-Free Reinforcement Learning.](http://proceedings.mlr.press/v139/zhang21e.html)
 - [[84]. FOP: Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/zhang21m.html)
 - [[85]. On-Policy Deep Reinforcement Learning for the Average-Reward Criterion.](http://proceedings.mlr.press/v139/zhang21q.html)
 - [[86]. MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration.](http://proceedings.mlr.press/v139/zhang21w.html)
 - [[87]. Model-Free Reinforcement Learning: from Clipped Pseudo-Regret to Sample Complexity.](http://proceedings.mlr.press/v139/zhang21ab.html)
 - [[88]. Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping.](http://proceedings.mlr.press/v139/zhou21a.html)
 - [[89]. Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v139/zimmer21a.html)
 - [[90]. Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning.](http://proceedings.mlr.press/v139/zintgraf21a.html)
