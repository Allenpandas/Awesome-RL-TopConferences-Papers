# 2021-NIPS Accepted Papers

  - [[1]. Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/000c076c390a4c357313fca29e390ece-Abstract.html)
 - [[2]. Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization.](https://proceedings.neurips.cc/paper/2021/hash/067a26d87265ea39030f5bd82408ce7c-Abstract.html)
 - [[3]. Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee.](https://proceedings.neurips.cc/paper/2021/hash/080acdcce72c06873a773c4311c2e464-Abstract.html)
 - [[4]. Risk-Averse Bayes-Adaptive Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/08f90c1a417155361a5c4b8d297e0d78-Abstract.html)
 - [[5]. Offline Reinforcement Learning as One Big Sequence Modeling Problem.](https://proceedings.neurips.cc/paper/2021/hash/099fe6b0b444c23836c4a5d07346082b-Abstract.html)
 - [[6]. Distributional Reinforcement Learning for Multi-Dimensional Reward Functions.](https://proceedings.neurips.cc/paper/2021/hash/0b9e57c46de934cee33b0e8d1839bfc2-Abstract.html)
 - [[7]. A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/0c215f194276000be6a6df6528067151-Abstract.html)
 - [[8]. Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation.](https://proceedings.neurips.cc/paper/2021/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html)
 - [[9]. There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/0e98aeeb54acf612b9eb4e48a269814c-Abstract.html)
 - [[10]. Reinforcement Learning in Reward-Mixing MDPs.](https://proceedings.neurips.cc/paper/2021/hash/11f9e78e4899a78dedd439fc583b6693-Abstract.html)
 - [[11]. Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/165a59f7cf3b5c4396ba65953d679f17-Abstract.html)
 - [[12]. On the Convergence Theory of Debiased Model-Agnostic Meta-Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/18085327b86002fc604c323b9a07f997-Abstract.html)
 - [[13]. Multi-Agent Reinforcement Learning for Active Voltage Control on Power Distribution Networks.](https://proceedings.neurips.cc/paper/2021/hash/1a6727711b84fd1efbb87fc565199d13-Abstract.html)
 - [[14]. On the Theory of Reinforcement Learning with Once-per-Episode Feedback.](https://proceedings.neurips.cc/paper/2021/hash/1bf2efbbe0c49b9f567c2e40f645279a-Abstract.html)
 - [[15]. On Effective Scheduling of Model-based Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/1e4d36177d71bbb3558e43af9577d70e-Abstract.html)
 - [[16]. Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration, Convergence, and Stabilization.](https://proceedings.neurips.cc/paper/2021/hash/1e79596878b2320cac26dd792a6c51c9-Abstract.html)
 - [[17]. Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration.](https://proceedings.neurips.cc/paper/2021/hash/1e8ca836c962598551882e689265c1c5-Abstract.html)
 - [[18]. Information Directed Reward Learning for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/1fa6269f58898f0e809575c9a48747ef-Abstract.html)
 - [[19]. Celebrating Diversity in Shared Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/20aee3a5f4643755a79ee5f6a73050ac-Abstract.html)
 - [[20]. Towards Instance-Optimal Offline Reinforcement Learning with Pessimism.](https://proceedings.neurips.cc/paper/2021/hash/212ab20dbdf4191cbcdcf015511783f4-Abstract.html)
 - [[21]. Environment Generation for Zero-Shot Compositional Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/218344619d8fb95d504ccfa11804073f-Abstract.html)
 - [[22]. Offline Meta Reinforcement Learning - Identifiability Challenges and Effective Data Collection Strategies.](https://proceedings.neurips.cc/paper/2021/hash/248024541dbda1d3fd75fe49d1a4df4d-Abstract.html)
 - [[23]. PlayVirtual: Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/2a38a4a9316c49e5a833517c45d31070-Abstract.html)
 - [[24]. Unifying Gradient Estimators for Meta-Reinforcement Learning via Off-Policy Evaluation.](https://proceedings.neurips.cc/paper/2021/hash/2a8009525763356ad5e3bb48b7475b4d-Abstract.html)
 - [[25]. Automatic Data Augmentation for Generalization in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/2b38c2df6a49b97f706ec9148ce48d86-Abstract.html)
 - [[26]. RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem.](https://proceedings.neurips.cc/paper/2021/hash/2bce32ed409f5ebcee2a7b417ad9beed-Abstract.html)
 - [[27]. Brick-by-Brick: Combinatorial Construction with Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/2d4027d6df9c0256b8d4474ce88f8c88-Abstract.html)
 - [[28]. Bellman-consistent Pessimism for Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/34f98c7c5d7063181da890ea8d25265a-Abstract.html)
 - [[29]. Teachable Reinforcement Learning via Advice Distillation.](https://proceedings.neurips.cc/paper/2021/hash/37cfff3c04f95b22bcf166df586cd7a9-Abstract.html)
 - [[30]. Inverse Reinforcement Learning in a Continuous State Space with Formal Guarantees.](https://proceedings.neurips.cc/paper/2021/hash/384babc3e7faa44cf1ca671b74499c3b-Abstract.html)
 - [[31]. Online Robust Reinforcement Learning with Model Uncertainty.](https://proceedings.neurips.cc/paper/2021/hash/3a4496776767aaa99f9804d0905fe584-Abstract.html)
 - [[32]. Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble.](https://proceedings.neurips.cc/paper/2021/hash/3d3d286a8d153a4a58156d0e02d8570c-Abstract.html)
 - [[33]. A Provably Efficient Sample Collection Strategy for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/3e98410c45ea98addec555019bbae8eb-Abstract.html)
 - [[34]. Near-Optimal Offline Reinforcement Learning via Double Variance Reduction.](https://proceedings.neurips.cc/paper/2021/hash/3f24bb08a5741e4197af64e1f93a5029-Abstract.html)
 - [[35]. Multi-Agent Reinforcement Learning in Stochastic Networked Systems.](https://proceedings.neurips.cc/paper/2021/hash/412604be30f701b1b1e3124c252065e6-Abstract.html)
 - [[36]. When Is Generalizable Reinforcement Learning Tractable?](https://proceedings.neurips.cc/paper/2021/hash/437d46a857214c997956eaf0e3b21a55-Abstract.html)
 - [[37]. Learning Markov State Abstractions for Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/454cecc4829279e64d624cd8a8c9ddf1-Abstract.html)
 - [[38]. Towards Deeper Deep Reinforcement Learning with Spectral Normalization.](https://proceedings.neurips.cc/paper/2021/hash/4588e674d3f0faf985047d4c3f13ed0d-Abstract.html)
 - [[39]. Adversarial Intrinsic Motivation for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/486c0401c56bf7ec2daa9eba58907da9-Abstract.html)
 - [[40]. Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/49e863b146f3b5470ee222ee84669b1c-Abstract.html)
 - [[41]. TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html)
 - [[42]. Model-Based Reinforcement Learning via Imagination with Derived Memory.](https://proceedings.neurips.cc/paper/2021/hash/4ebccfb3e317c7789f04f7a558df4537-Abstract.html)
 - [[43]. Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/517f24c02e620d5a4dac1db388664a63-Abstract.html)
 - [[44]. Compositional Reinforcement Learning from Logical Specifications.](https://proceedings.neurips.cc/paper/2021/hash/531db99cb00833bcd414459069dc7387-Abstract.html)
 - [[45]. Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/550a141f12de6341fba65b0ad0433500-Abstract.html)
 - [[46]. Local Differential Privacy for Regret Minimization in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/580760fb5def6e2ca8eaf601236d5b08-Abstract.html)
 - [[47]. Continuous Doubly Constrained Batch Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/5da713a690c067105aeb2fae32403405-Abstract.html)
 - [[48]. Conservative Data Sharing for Multi-Task Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/5fd2c06f558321eff612bbbe455f6fbd-Abstract.html)
 - [[49]. Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism.](https://proceedings.neurips.cc/paper/2021/hash/60ce36723c17bbac504f2ef4c8a46995-Abstract.html)
 - [[50]. A Provably Efficient Model-Free Posterior Sampling Method for Episodic Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/649d45bf179296e31731adfd4df25588-Abstract.html)
 - [[51]. Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/6531b32f8d02fece98ff36a64a7c8260-Abstract.html)
 - [[52]. EDGE: Explaining Deep Reinforcement Learning Policies.](https://proceedings.neurips.cc/paper/2021/hash/65c89f5a9501a04c073b354f03791b1f-Abstract.html)
 - [[53]. Provably Efficient Black-Box Action Poisoning Attacks Against Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/678004486c119599ed7d199f47da043a-Abstract.html)
 - [[54]. Cross-modal Domain Adaptation for Cost-Efficient Visual Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/68264bdb65b97eeae6788aa3348e553c-Abstract.html)
 - [[55]. Pretraining Representations for Data-Efficient Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/69eba34671b3ef1ef38ee85caae6b2a1-Abstract.html)
 - [[56]. Tactical Optimism and Pessimism for Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/6abcc8f24321d1eb8c95855eab78ee95-Abstract.html)
 - [[57]. Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/6add07cf50424b14fdf649da87843d01-Abstract.html)
 - [[58]. Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings.](https://proceedings.neurips.cc/paper/2021/hash/6b3c49bdba5be0d322334e30c459f8bd-Abstract.html)
 - [[59]. Outcome-Driven Reinforcement Learning via Variational Inference.](https://proceedings.neurips.cc/paper/2021/hash/6cdd60ea0045eb7a6ec44c54d29ed402-Abstract.html)
 - [[60]. Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/6d7d394c9d0c886e9247542e06ebb705-Abstract.html)
 - [[61]. Provably Efficient Reinforcement Learning with Linear Function Approximation under Adaptivity Constraints.](https://proceedings.neurips.cc/paper/2021/hash/70a32110fff0f26d301e58ebbca9cb9f-Abstract.html)
 - [[62]. Heuristic-Guided Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/70d31b87bd021441e5e6bf23eb84a306-Abstract.html)
 - [[63]. Provable Benefits of Actor-Critic Methods for Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/713fd63d76c8a57b16fc433fb4ae718a-Abstract.html)
 - [[64]. Safe Reinforcement Learning with Natural Language Constraints.](https://proceedings.neurips.cc/paper/2021/hash/72f67e70f6b7cdc4cc893edaddf0c4c6-Abstract.html)
 - [[65]. Safe Reinforcement Learning by Imagining the Near Future.](https://proceedings.neurips.cc/paper/2021/hash/73b277c11266681122132d024f53a75b-Abstract.html)
 - [[66]. Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation.](https://proceedings.neurips.cc/paper/2021/hash/7695ea769f021803c508817dd374bb27-Abstract.html)
 - [[67]. MAP Propagation Algorithm: Faster Learning with a Team of Reinforcement Learning Agents.](https://proceedings.neurips.cc/paper/2021/hash/7c05147f3029c97ce26c0cb0b2469fca-Abstract.html)
 - [[68]. PettingZoo: Gym for Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/7ed2d3454c5eea71148b11d0c25104ff-Abstract.html)
 - [[69]. Decision Transformer: Reinforcement Learning via Sequence Modeling.](https://proceedings.neurips.cc/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html)
 - [[70]. Nearly Horizon-Free Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/8396b14c5dff55d13eea57487bf8ed26-Abstract.html)
 - [[71]. Reinforcement Learning with State Observation Costs in Action-Contingent Noiselessly Observable Markov Decision Processes.](https://proceedings.neurips.cc/paper/2021/hash/83e8fe6279ad25f15b23c6298c6a3584-Abstract.html)
 - [[72]. Contrastive Reinforcement Learning of Symbolic Reasoning Domains.](https://proceedings.neurips.cc/paper/2021/hash/859555c74e9afd45ab771c615c1e49a6-Abstract.html)
 - [[73]. Reinforcement Learning in Linear MDPs: Constant Regret and Representation Selection.](https://proceedings.neurips.cc/paper/2021/hash/8860e834a67da41edd6ffe8a1c58fa55-Abstract.html)
 - [[74]. Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting.](https://proceedings.neurips.cc/paper/2021/hash/8b5700012be65c9da25f49408d959ca0-Abstract.html)
 - [[75]. Scalable Online Planning via Reinforcement Learning Fine-Tuning.](https://proceedings.neurips.cc/paper/2021/hash/8ce8b102d40392a688f8c04b3cd6cae0-Abstract.html)
 - [[76]. An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/8d9a6e908ed2b731fb96151d9bb94d49-Abstract.html)
 - [[77]. Risk-Aware Transfer in Reinforcement Learning using Successor Features.](https://proceedings.neurips.cc/paper/2021/hash/90610aa0e24f63ec6d2637e06f9b9af2-Abstract.html)
 - [[78]. Regret Minimization Experience Replay in Off-Policy Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/931af583573227f0220bc568c65ce104-Abstract.html)
 - [[79]. Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/94739e5a5164b4d2396e253a11d57044-Abstract.html)
 - [[80]. A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/955fd82131e15e7b5199cbc8f983306a-Abstract.html)
 - [[81]. Autonomous Reinforcement Learning via Subgoal Curricula.](https://proceedings.neurips.cc/paper/2021/hash/99c83c904d0d64fbef50d919a5c66a80-Abstract.html)
 - [[82]. PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators.](https://proceedings.neurips.cc/paper/2021/hash/9a3f263a5e5f63006098a05cd7491997-Abstract.html)
 - [[83]. Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/9c51a13764ca629f439f6accbb4ec413-Abstract.html)
 - [[84]. Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations.](https://proceedings.neurips.cc/paper/2021/hash/9eed867b73ab1eab60583c9d4a789b1b-Abstract.html)
 - [[85]. Functional Regularization for Reinforcement Learning via Learned Fourier Features.](https://proceedings.neurips.cc/paper/2021/hash/9f0609b9d45dd55bed75f892cf095fcf-Abstract.html)
 - [[86]. Agent Modelling under Partial Observability for Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/a03caec56cd82478bf197475b48c05f9-Abstract.html)
 - [[87]. Conservative Offline Distributional Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/a05d886123a54de3ca4b0985b718fb9b-Abstract.html)
 - [[88]. Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/a35fe7f7fe8217b4369a0af4244d1fca-Abstract.html)
 - [[89]. Explicable Reward Design for Reinforcement Learning Agents.](https://proceedings.neurips.cc/paper/2021/hash/a7f0d2b95c60161b3f3c82f764b1d1c9-Abstract.html)
 - [[90]. A Minimalist Approach to Offline Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/a8166da05c5a094f7dc03724b41886e5-Abstract.html)
 - [[91]. BCORLE(λ): An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market.](https://proceedings.neurips.cc/paper/2021/hash/ab452534c5ce28c4fbb0e102d4a4fb2e-Abstract.html)
 - [[92]. Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/ab6439fa2daf0246f92eea433bca5ac4-Abstract.html)
 - [[93]. Reinforcement Learning based Disease Progression Model for Alzheimer's Disease.](https://proceedings.neurips.cc/paper/2021/hash/af1c25e88a9e818f809f6b5d18ca02e2-Abstract.html)
 - [[94]. Accelerating Quadratic Optimization with Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/afdec7005cc9f14302cd0474fd0f3c96-Abstract.html)
 - [[95]. Provably Efficient Causal Reinforcement Learning with Confounded Observational Data.](https://proceedings.neurips.cc/paper/2021/hash/b0b79da57b95837f14be95aaa4d54cf8-Abstract.html)
 - [[96]. Hierarchical Reinforcement Learning with Timed Subgoals.](https://proceedings.neurips.cc/paper/2021/hash/b59c21a078fde074a6750e91ed19fb21-Abstract.html)
 - [[97]. Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives.](https://proceedings.neurips.cc/paper/2021/hash/b6846b0186a035fcc76b1b1d26fd42fa-Abstract.html)
 - [[98]. Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation.](https://proceedings.neurips.cc/paper/2021/hash/b6f8dc086b2d60c5856e4ff517060392-Abstract.html)
 - [[99]. Reinforcement Learning in Newcomblike Environments.](https://proceedings.neurips.cc/paper/2021/hash/b9ed18a301c9f3d183938c451fa183df-Abstract.html)
 - [[100]. Reinforcement Learning with Latent Flow.](https://proceedings.neurips.cc/paper/2021/hash/ba3c5fe1d6d6708b5bffaeb6942b7e04-Abstract.html)
 - [[101]. Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs.](https://proceedings.neurips.cc/paper/2021/hash/bb57db42f77807a9c5823bd8c2d9aaef-Abstract.html)
 - [[102]. Reinforcement Learning Enhanced Explainer for Graph Neural Networks.](https://proceedings.neurips.cc/paper/2021/hash/be26abe76fb5c8a4921cf9d3e865b454-Abstract.html)
 - [[103]. The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/be3e9d3f7d70537357c67bb3f4086846-Abstract.html)
 - [[104]. Causal Influence Detection for Improving Efficiency in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/c1722a7941d61aad6e651a35b65a9c3e-Abstract.html)
 - [[105]. Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs with a Generative Model.](https://proceedings.neurips.cc/paper/2021/hash/c21f4ce780c5c9d774f79841b81fdc6d-Abstract.html)
 - [[106]. RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents.](https://proceedings.neurips.cc/paper/2021/hash/c2626d850c80ea07e7511bbae4c76f4b-Abstract.html)
 - [[107]. The Difficulty of Passive Learning in Deep Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/c3e0c62ee91db8dc7382bde7419bb573-Abstract.html)
 - [[108]. A Hierarchical Reinforcement Learning Based Optimization Framework for Large-scale Dynamic Pickup and Delivery Problems.](https://proceedings.neurips.cc/paper/2021/hash/c6a01432c8138d46ba39957a8250e027-Abstract.html)
 - [[109]. Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding.](https://proceedings.neurips.cc/paper/2021/hash/d073bb8d0c47f317dd39de9c9f004e9d-Abstract.html)
 - [[110]. Machine versus Human Attention in Deep Reinforcement Learning Tasks.](https://proceedings.neurips.cc/paper/2021/hash/d58e2f077670f4de9cd7963c857f2534-Abstract.html)
 - [[111]. Offline Constrained Multi-Objective Reinforcement Learning via Pessimistic Dual Value Iteration.](https://proceedings.neurips.cc/paper/2021/hash/d5c8e1ab6fc0bfeb5f29aafa999cdb29-Abstract.html)
 - [[112]. Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations.](https://proceedings.neurips.cc/paper/2021/hash/d71fa38b648d86602d14ac610f2e6194-Abstract.html)
 - [[113]. A Max-Min Entropy Framework for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/d7b76edf790923bf7177f7ebba5978df-Abstract.html)
 - [[114]. Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch.](https://proceedings.neurips.cc/paper/2021/hash/d9e74f47610385b11e295eec4c58d473-Abstract.html)
 - [[115]. Robust Deep Reinforcement Learning through Adversarial Loss.](https://proceedings.neurips.cc/paper/2021/hash/dbb422937d7ff56e049d61da730b3e11-Abstract.html)
 - [[116]. Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature.](https://proceedings.neurips.cc/paper/2021/hash/dc5d637ed5e62c36ecb73b654b05ba2a-Abstract.html)
 - [[117]. Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings.](https://proceedings.neurips.cc/paper/2021/hash/e140dbab44e01e699491a59c9978b924-Abstract.html)
 - [[118]. Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/e27c71957d1e6c223e0d48a165da2ee1-Abstract.html)
 - [[119]. Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/e61eaa38aed621dd776d0e67cfeee366-Abstract.html)
 - [[120]. Online and Offline Reinforcement Learning by Planning with a Learned Model.](https://proceedings.neurips.cc/paper/2021/hash/e8258e5140317ff36c7f8225a3bf9590-Abstract.html)
 - [[121]. Variational Bayesian Reinforcement Learning with Regret Bounds.](https://proceedings.neurips.cc/paper/2021/hash/edb446b67d69adbfe9a21068982000c2-Abstract.html)
 - [[122]. Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/ee39e503b6bedf0c98c388b7e8589aca-Abstract.html)
 - [[123]. Parametrized Quantum Policies for Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/eec96a7f788e88184c0e713456026f3f-Abstract.html)
 - [[124]. On Pathologies in KL-Regularized Reinforcement Learning from Expert Demonstrations.](https://proceedings.neurips.cc/paper/2021/hash/eecca5b6365d9607ee5a9d336962c534-Abstract.html)
 - [[125]. Continual World: A Robotic Benchmark For Continual Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/ef8446f35513a8d6aa2308357a268a7e-Abstract.html)
 - [[126]. Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/f187a23c3ee681ef6913f31fd6d6446b-Abstract.html)
 - [[127]. Deep Reinforcement Learning at the Edge of the Statistical Precipice.](https://proceedings.neurips.cc/paper/2021/hash/f514cec81cb148559cf475e7426eed5e-Abstract.html)
 - [[128]. Offline Reinforcement Learning with Reverse Model-based Imagination.](https://proceedings.neurips.cc/paper/2021/hash/f5e647292cc4e1064968ca62bebe7e47-Abstract.html)
 - [[129]. Program Synthesis Guided Reinforcement Learning for Partially Observed Environments.](https://proceedings.neurips.cc/paper/2021/hash/f7e2b2b75b04175610e5a00c1e221ebb-Abstract.html)
 - [[130]. Structural Credit Assignment in Neural Networks using Reinforcement Learning.](https://proceedings.neurips.cc/paper/2021/hash/fe1f9c70bdf347497e1a01b6c486bdb9-Abstract.html)
