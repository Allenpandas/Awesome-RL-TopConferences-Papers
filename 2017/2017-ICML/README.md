# 2017-ICML Accepted Papers

- [[1]. Modular Multitask Reinforcement Learning with Policy Sketches.](http://proceedings.mlr.press/v70/andreas17a.html)
- [[2]. Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning.](http://proceedings.mlr.press/v70/anschel17a.html)
- [[3]. An Alternative Softmax Operator for Reinforcement Learning.](http://proceedings.mlr.press/v70/asadi17a.html)
- [[4]. Minimax Regret Bounds for Reinforcement Learning.](http://proceedings.mlr.press/v70/azar17a.html)
- [[5]. A Distributional Perspective on Reinforcement Learning.](http://proceedings.mlr.press/v70/bellemare17a.html)
- [[6]. Neural Optimizer Search with Reinforcement Learning.](http://proceedings.mlr.press/v70/bello17a.html)
- [[7]. Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning.](http://proceedings.mlr.press/v70/chebotar17a.html)
- [[8]. Improving Stochastic Policy Gradients in Continuous Control with Deep Reinforcement Learning using the Beta Distribution.](http://proceedings.mlr.press/v70/chou17a.html)
- [[9]. Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning.](http://proceedings.mlr.press/v70/foerster17b.html)
- [[10]. Reinforcement Learning with Deep Energy-Based Policies.](http://proceedings.mlr.press/v70/haarnoja17a.html)
- [[11]. DARLA: Improving Zero-Shot Transfer in Reinforcement Learning.](http://proceedings.mlr.press/v70/higgins17a.html)
- [[12]. Fairness in Reinforcement Learning.](http://proceedings.mlr.press/v70/jabbari17a.html)
- [[13]. A Laplacian Framework for Option Discovery in Reinforcement Learning.](http://proceedings.mlr.press/v70/machado17a.html)
- [[14]. Device Placement Optimization with Reinforcement Learning.](http://proceedings.mlr.press/v70/mirhoseini17a.html)
- [[15]. Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning.](http://proceedings.mlr.press/v70/oh17a.html)
- [[16]. Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability.](http://proceedings.mlr.press/v70/omidshafiei17a.html)
- [[17]. Why is Posterior Sampling Better than Optimism for Reinforcement Learning?](http://proceedings.mlr.press/v70/osband17a.html)
- [[18]. Robust Adversarial Reinforcement Learning.](http://proceedings.mlr.press/v70/pinto17a.html)
- [[19]. FeUdal Networks for Hierarchical Reinforcement Learning.](http://proceedings.mlr.press/v70/vezhnevets17a.html)
- [[20]. Unifying Task Specification in Reinforcement Learning.](http://proceedings.mlr.press/v70/white17a.html)
